# Software

```{image} images/model_crop.png
:name: Atmospheric Model
```
[*Image from William Putman/NASA Goddard Space Flight Center*](https://www.nasa.gov/content/a-portrait-of-global-winds)  

## Python

I mainly use Python (primary libraries: Numpy, xarray, Pandas, Matplotlib, Jupyter, Dask) to analyse the large amounts of data produced by complex air quality models.  

I provided training for scientific computing (Python, Linux, and GitHub). For example, [explaining](https://www.lukeconibear.com/introduction_to_scientific_computing/tips_to_speed_up_python.html) how to speed up Python code.  

I taught and provided support for [epidemiological models](https://github.com/lukeconibear/health_impact_assessment).  

I used machine learning models (Gaussian process emulation trained from ~20 TB of simulated data) to predict optimum emission reduction strategies to improve air quality and public health in China ([code](https://github.com/lukeconibear/emulator) using scitkit-learn and TPOT, [academic paper](https://doi.org/10.1029/2021GH000391)).  

[Here](https://www.kaggle.com/lukeconibear/house-prices-simple-guide) is a simple guide to Kaggle's House Price competition.  

I quantified how clean household energy can improve air quality and public health in India ([interactive map](/plot_india_solid_fuel)).  

## WRFChem

I taught and provided support for a [complex air quality model](https://wrfchem-leeds.github.io/WRFotron/) (Bash and Fortran).  
